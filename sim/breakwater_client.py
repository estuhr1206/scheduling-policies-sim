#!/usr/bin/env python
"""client object for instances of clients in the breakwater system."""

import math
from collections import deque
import random
import numpy as np

# clients are initialized in simulation_state.py, (similar to items like the sim_queues)
# list of them can be accessed in main simulation, from sim.state


class BreakwaterClient:

    def __init__(self, state, identifier):
        # Where tasks from task creation are placed once they have "arrived"
        self.queue = deque()
        # credits are incremented by server, decremented(used) by client. used as Cx from paper calculations
        # self.credits = 0
        # v3, adding in concept of credits in use and credits unused
        self.window = 0
        self.c_in_use = 0
        self.c_unused = 0
        # equivalent to number of requests in queue
        self.current_demand = 0
        self.registered = False
        self.state = state
        self.dropped_tasks = 0
        self.timed_out_tasks = 0
        self.total_tasks = 0
        self.drops_record = []
        self.tasks_spent_control_loop = 0

        self.timeout = 2 * int(10 * (self.state.config.RTT + self.state.config.AVERAGE_SERVICE_TIME))

        self.dropped_credits = 0

        self.id = identifier
        self.granularity = self.state.config.BREAKWATER_GRANULARITY
        # currently, 100,000 microseconds in 0.1 seconds of simulated time
        # can adjust if sim time is changing.
        self.total_intervals = int(self.state.config.sim_duration / self.granularity)
        self.dropped_credits_map = np.zeros((self.total_intervals + 1))
        self.success_credits_map = np.zeros((self.total_intervals + 1))

    def enqueue_task(self, task):
        self.queue.append(task)
        self.current_demand += 1
        self.total_tasks += 1
        if not self.registered:
            self.state.breakwater_server.client_register(self)
            self.registered = True
        # can be called from simulation, using the task generated by simulation state's initialize
        # tasks from that main list will get enqueued at random clients

        # should call spend_credits
        self.client_control_loop()

    def spend_credits(self):

        # aqm can happen here, simply don't enqueue it at a core if delay is high
        # self.state.breakwater_server.credits_issued -= 1
        self.c_unused -= 1
        self.c_in_use += 1

        current_task = self.queue.popleft()
        # self.current_demand -= 1

        # check for aqm, if aqm, add some stat for request got dropped
        # breakwater paper: "AQM threshold to 2 · dt (e.g., dt = 80 μs and AQM threshold = 160 μs)"
        # TODO changing to use current system delay info
        """
            option1: use max delay of queues
            option2: use delay of chosen queue
        """
        chosen_queue = random.choice(self.state.available_queues)
        # delay = self.state.queues[chosen_queue].current_delay()
        delay = self.state.max_queue_delay()[0]
        # always mark arrival time in order to trace runs better
        current_task.arrival_time = self.state.timer.get_time()
        if self.state.config.no_drops:
            # allow enqueue to occur no matter what
            delay = 0
        if delay <= 2 * self.state.config.BREAKWATER_TARGET_DELAY:
            # need to override arrival time for core usage
            # this is ok, because the arrival time usage for enqueuing at clients occurs before this
            # override here
            # current_task.arrival_time = self.state.timer.get_time()
            current_task.source_client = self.id
            # enqueue at core
            self.state.queues[chosen_queue].enqueue(current_task, set_original=True)
        else:
            # shouldn't be dropped if load is low (aka the 50%)
            self.c_in_use -= 1
            self.dropped_tasks += 1
            self.dropped_credits += 1
            current_time = self.state.timer.get_time()
            time_g = int(current_time / self.granularity) + int(self.state.config.RTT / self.granularity)
            if time_g < self.total_intervals + 1:
                self.dropped_credits_map[time_g] += 1
            if self.state.config.record_drops:
                delay_tuple = self.state.max_queue_delay()
                length_tuple = self.state.max_queue_length()
                self.drops_record.append([current_time, len(self.state.available_queues), self.state.breakwater_server.total_credits,
                                          delay_tuple[0], delay_tuple[1], length_tuple[0], length_tuple[1], self.state.total_queue_occupancy(), 
                                          self.window, self.c_in_use, self.dropped_credits, self.current_demand, len(self.queue)])
            if self.state.config.record_queue_lens:
                self.state.record_queue_lengths()
            return False
        # TODO deregister is off for now
        # may have just finished our last task
        # if self.current_demand <= 0:
            # self.deregister()
        return True
    
    def client_control_loop(self, from_server=False):
        if self.current_demand < 0:
            raise ValueError('error, demand was below 0')
        if self.state.config.request_timeout:
            while len(self.queue) > 0:
                current_task = self.queue[0]
                if current_task.arrival_time <= self.state.timer.get_time() - self.timeout:
                    self.queue.popleft()
                    self.current_demand -= 1
                    self.timed_out_tasks += 1
                else:
                    break

        self.c_unused = self.window - (self.c_in_use + self.dropped_credits)
        while len(self.queue) > 0 and self.c_unused > 0:
            if from_server:
                self.tasks_spent_control_loop += 1
            self.spend_credits()

    # simplify debugging, don't deregister
    def deregister(self):
        # important that this call to server is first, as it will take back credits the client currently has
        # I think it should just be window that gets subtracted from issued
        #self.c_unused = self.window - self.c_in_use
        self.state.breakwater_server.client_deregister(self)
        self.registered = False
        self.c_unused = 0
        self.window = 0

    def restore_dropped_credits(self):
        current_interval = int(self.state.timer.get_time() / self.granularity)
        num_dropped = self.dropped_credits_map[current_interval]
        if num_dropped > 0:
            self.dropped_credits -= num_dropped
            self.current_demand -= num_dropped
            return True
        return False
        # TODO add client reattempts for failed tasks?

    def check_successes(self):
        current_time = self.state.timer.get_time()
        current_interval = int(current_time / self.granularity)
        num_successes = self.success_credits_map[current_interval]
        if num_successes > 0:
            """
                a bit odd to call this here, but server side logic is still
                instant.
                This call to the server represents that the server would have
                done the lazy distribution when the task completed at the server.

                The response has been delayed by an RTT to the client, therefore,
                here we are delayed by an RTT at the client, so we may have the server
                do this instantly to simulate it simply being delayed an RTT

                edit: I don't think this matters-, so swapping to not need another client control
                loop call
                    note: this means that the client in use credits ought to be updated AFTER
                    the server call
            """
            self.c_in_use -= num_successes
            self.current_demand -= num_successes
            return True
        return False
            



